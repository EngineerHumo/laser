import torch
import sys

print("=" * 60)
print("PyTorch CUDA å®‰è£…éªŒè¯")
print("=" * 60)
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"Pythonç‰ˆæœ¬: {sys.version}")
print(f"CUDAæ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    print(f"å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    
    # å®é™…GPUè®¡ç®—æµ‹è¯•
    device = torch.device('cuda')
    x = torch.randn(1000, 1000).to(device)
    y = torch.randn(1000, 1000).to(device)
    z = torch.matmul(x, y)
    print(f"GPUè®¡ç®—æµ‹è¯•æˆåŠŸ: çŸ©é˜µä¹˜æ³•ç»“æœå½¢çŠ¶ {z.shape}")
    print("ğŸ‰ PyTorch CUDAå®‰è£…å®Œå…¨æˆåŠŸï¼")
else:
    print("âŒ è¿˜æœ‰é—®é¢˜ï¼ŒCUDAä»ä¸å¯ç”¨")